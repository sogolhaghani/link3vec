{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 19:35:09.045836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 19:35:10.706001: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-19 19:35:10.707235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-19 19:35:10.746346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:10.746615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-02-19 19:35:10.746640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-19 19:35:10.748766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-19 19:35:10.748997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-02-19 19:35:10.752644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-19 19:35:10.753239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-19 19:35:10.755855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-19 19:35:10.757381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-19 19:35:10.763122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-19 19:35:10.763295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:10.763629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:10.763839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-02-19 19:35:10.764269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-19 19:35:10.765034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:10.765257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-02-19 19:35:10.765293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-19 19:35:10.765318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-19 19:35:10.765335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-02-19 19:35:10.765351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-19 19:35:10.765367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-19 19:35:10.765383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-19 19:35:10.765400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-19 19:35:10.765417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-19 19:35:10.765483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:10.765720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:10.765896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-02-19 19:35:10.765932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-19 19:35:11.580005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-19 19:35:11.580047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-02-19 19:35:11.580057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-02-19 19:35:11.580295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:11.580640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:11.580936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 19:35:11.581180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5080 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-02-19 19:35:11.581517: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "train = np.load('../data/WN18_numpy/train.npy')\n",
    "validation = np.load('../data/WN18_numpy/validation.npy')\n",
    "test = np.load('../data/WN18_numpy/test.npy')\n",
    "\n",
    "entities = np.load('../data/WN18_numpy/entities.npy')\n",
    "relations = np.load('../data/WN18_numpy/relations.npy')\n",
    "\n",
    "train = tf.convert_to_tensor(train.astype(dtype=np.int64), dtype=tf.int64)\n",
    "validation = tf.convert_to_tensor(validation.astype(dtype=np.int64), dtype=tf.int64)\n",
    "test = tf.convert_to_tensor(test.astype(dtype=np.int64), dtype=tf.int64)\n",
    "relations = tf.convert_to_tensor(relations.astype(dtype=np.float64), dtype=tf.float64)\n",
    "entities = tf.convert_to_tensor(entities.astype(dtype=np.float64), dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18, 3), dtype=float64, numpy=\n",
       "array([[0.00000000e+00, 1.29900000e+03, 1.69525570e-02],\n",
       "       [1.00000000e+00, 2.97150000e+04, 1.77320992e-01],\n",
       "       [2.00000000e+00, 4.81600000e+03, 4.52942642e-02],\n",
       "       [3.00000000e+00, 3.47960000e+04, 1.99606804e-01],\n",
       "       [4.00000000e+00, 3.48320000e+04, 1.99761670e-01],\n",
       "       [5.00000000e+00, 2.92100000e+03, 3.11298493e-02],\n",
       "       [6.00000000e+00, 2.93500000e+03, 3.12416836e-02],\n",
       "       [7.00000000e+00, 7.38200000e+03, 6.23963063e-02],\n",
       "       [8.00000000e+00, 7.40200000e+03, 6.25230508e-02],\n",
       "       [9.00000000e+00, 9.23000000e+02, 1.31198729e-02],\n",
       "       [1.00000000e+01, 3.11800000e+03, 3.26915441e-02],\n",
       "       [1.10000000e+01, 6.29000000e+02, 9.84048117e-03],\n",
       "       [1.20000000e+01, 4.80500000e+03, 4.52166512e-02],\n",
       "       [1.30000000e+01, 8.00000000e+01, 2.09578072e-03],\n",
       "       [1.40000000e+01, 9.03000000e+02, 1.29060744e-02],\n",
       "       [1.50000000e+01, 3.11600000e+03, 3.26758156e-02],\n",
       "       [1.60000000e+01, 6.32000000e+02, 9.87566067e-03],\n",
       "       [1.70000000e+01, 1.13800000e+03, 1.53509426e-02]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = tf.constant(20)\n",
    "dim = tf.constant(100)\n",
    "kns = tf.constant(5)\n",
    "kns_r = tf.constant(2)\n",
    "alpha = tf.Variable(0.01, dtype = tf.float64)\n",
    "beta = tf.Variable(0.0001, dtype = tf.float64)\n",
    "z = tf.constant(5, dtype = tf.float64)\n",
    "nn1 = tf.random.uniform( shape=(entities.shape[0], dim),\n",
    "      # minval=tf.math.truediv(z , tf.cast(dim,tf.float64),'minval'), \n",
    "      maxval=tf.math.truediv(z , tf.cast(dim,tf.float64),'maxval'),\n",
    "      dtype=tf.dtypes.float64, seed=None, name='nn1')\n",
    "      \n",
    "nn0 =tf.random.uniform(shape=(entities.shape[0], dim), \n",
    "      # minval=tf.math.truediv(z , tf.cast(dim,tf.float64),'minval'), \n",
    "      maxval=tf.math.truediv(z , tf.cast(dim,tf.float64),'maxval'),\n",
    "      dtype=tf.dtypes.float64, seed=None, name='nn0')\n",
    "nn2 = tf.random.uniform(shape=(relations.shape[0], dim), \n",
    "      # minval=tf.math.truediv(z , tf.cast(dim,tf.float64),'minval'), \n",
    "      maxval=tf.math.truediv(z , tf.cast(dim,tf.float64),'maxval'),\n",
    "      dtype=tf.dtypes.float64, seed=None, name='nn2')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def calculateRank(triple):  \n",
    "    start = time.time() \n",
    "    selectedEntities = tf.cast(tf.gather(entities, 0, axis=1), dtype=tf.int64)\n",
    "    _head_index = tf.gather(triple,0)\n",
    "    _tail_index = tf.gather(triple,1)\n",
    "    _relation_index = tf.gather(triple,2)  \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(train, 1, axis=1) == _tail_index) , (tf.gather(train, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(train, indexes), 0, axis=1)\n",
    "    shape = tf.constant([entities.shape[0]], dtype=tf.int64)   \n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTrain = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "\n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(test, 1, axis=1) == _tail_index) , (tf.gather(test, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(test, indexes), 0, axis=1)\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTest = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(validation, 1, axis=1) == _tail_index) , (tf.gather(validation, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(validation, indexes), 0, axis=1)\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesvalidation = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "\n",
    "    selectedEntitiesTrain= tf.reshape(selectedEntitiesTrain, (1, selectedEntitiesTrain.shape[0]))\n",
    "    selectedEntitiesTest = tf.reshape(selectedEntitiesTest, (1, selectedEntitiesTest.shape[0]))\n",
    "    selectedEntitiesvalidation = tf.reshape(selectedEntitiesvalidation, (1, selectedEntitiesvalidation.shape[0]))\n",
    "    selectedEntitiesFinal = tf.sets.intersection(selectedEntitiesTrain, selectedEntitiesTest)\n",
    "    selectedEntitiesFinal = tf.cast(tf.sets.intersection(selectedEntitiesFinal, selectedEntitiesvalidation), dtype=tf.int64).values\n",
    "    couraptedH = tf.concat([  tf.reshape(selectedEntitiesFinal, (selectedEntitiesFinal.shape[0], 1)) , tf.fill([selectedEntitiesFinal.shape[0], 1], _tail_index) , tf.fill([selectedEntitiesFinal.shape[0], 1], _relation_index)],1)\n",
    "    couraptedH = tf.concat([couraptedH, tf.reshape(triple, (1,3))], 0)\n",
    "    indexes = None\n",
    "    existEntites = None\n",
    "    selectedEntitiesTrain = None\n",
    "    selectedEntitiesTest = None\n",
    "    selectedEntitiesvalidation = None\n",
    "    selectedEntitiesFinal = None\n",
    "    div = tf.constant(3)\n",
    "    sliceSize = tf.cast(tf.math.floor(tf.math.truediv(couraptedH.shape[0], div)),dtype=tf.int64)\n",
    "    s0, s1, s2= tf.split(couraptedH, num_or_size_splits=[\n",
    "        sliceSize , \n",
    "        sliceSize , \n",
    "        tf.math.subtract(couraptedH.shape[0] , tf.math.multiply(sliceSize, 2)) ], axis=0)\n",
    "    couraptedH = None\n",
    "    p0 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s0,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s0,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p1 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s1,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s1,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p2 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s2,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s2,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p = tf.concat([p0,p1,p2,], 0)\n",
    "    rankH = tf.where(tf.math.top_k( p ,k = p.shape[0]).indices  == tf.subtract(p.shape[0] , 1) )\n",
    "    \n",
    "    p0 = None\n",
    "    p1 = None\n",
    "    p2 = None\n",
    "    p = None\n",
    "\n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(train, 0, axis=1) == _head_index) , (tf.gather(train, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(train, indexes), 1, axis=1)\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTrain = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(test, 0, axis=1) == _head_index) , (tf.gather(test, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(test, indexes), 1, axis=1)\n",
    "\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTest = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(validation, 0, axis=1) == _head_index) , (tf.gather(validation, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(validation, indexes), 1, axis=1)\n",
    "\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesvalidation = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    selectedEntitiesTrain= tf.reshape(selectedEntitiesTrain, (1, selectedEntitiesTrain.shape[0]))\n",
    "    selectedEntitiesTest = tf.reshape(selectedEntitiesTest, (1, selectedEntitiesTest.shape[0]))\n",
    "    selectedEntitiesvalidation = tf.reshape(selectedEntitiesvalidation, (1, selectedEntitiesvalidation.shape[0]))\n",
    "\n",
    "    selectedEntitiesFinal = tf.sets.intersection(selectedEntitiesTrain, selectedEntitiesTest)\n",
    "    selectedEntitiesFinal = tf.cast(tf.sets.intersection(selectedEntitiesFinal, selectedEntitiesvalidation), dtype=tf.int64).values\n",
    "    couraptedT = tf.concat([   tf.fill([selectedEntitiesFinal.shape[0], 1], _head_index) , tf.reshape(selectedEntitiesFinal, (selectedEntitiesFinal.shape[0], 1)) , tf.fill([selectedEntitiesFinal.shape[0], 1], _relation_index)],1)\n",
    "    couraptedT = tf.concat([couraptedT, tf.reshape(triple, (1,3))], 0)    \n",
    "    indexes = None\n",
    "    existEntites = None\n",
    "    selectedEntitiesTrain = None\n",
    "    selectedEntitiesTest = None\n",
    "    selectedEntitiesvalidation = None\n",
    "    selectedEntitiesFinal = None\n",
    "    div = tf.constant(3)\n",
    "    sliceSize = tf.cast(tf.math.floor(tf.math.truediv(couraptedT.shape[0], div)),dtype=tf.int64)\n",
    "    s0, s1, s2= tf.split(couraptedT, num_or_size_splits=[\n",
    "        sliceSize , \n",
    "        sliceSize , \n",
    "        tf.math.subtract(couraptedT.shape[0] , tf.math.multiply(sliceSize, 2)) ], axis=0)\n",
    "    couraptedT = None\n",
    "    p0 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s0,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s0,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p1 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s1,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s1,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p2 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s2,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s2,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p = tf.concat([p0,p1,p2,], 0)\n",
    "    rankT = tf.where(tf.math.top_k( p ,k = p.shape[0]).indices  == tf.subtract(p.shape[0] , 1) )\n",
    "    p = None\n",
    "    # print(rankH, rankT)\n",
    "    if tf.math.greater(rankH , rankT):\n",
    "        return tf.math.add(rankT,1)\n",
    "    else:\n",
    "        return tf.math.add(rankH,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(ranks):\n",
    "    inverse = []\n",
    "    one = tf.constant(1.0, dtype = tf.float64)\n",
    "    for rank in ranks:\n",
    "        inverse.append( tf.math.truediv(one , tf.cast(rank,tf.float64)))\n",
    "    summ = tf.reduce_sum(inverse)\n",
    "    return tf.math.multiply(tf.math.truediv(one , len(inverse)) , summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampleling_tail(nn0, nn1, nn2):\n",
    "    paddings = tf.constant([[0, 1,], [0, 0]])\n",
    "    t_row = 10000#train.shape[0]\n",
    "    with tf.device('/cpu:0'):\n",
    "        total_samples  = tf.gather( tf.random.categorical([tf.gather(entities, 2, axis=1)], tf.math.multiply(kns,t_row) , dtype=None, seed=None),0)\n",
    "    for tIndex in range(0 , t_row):\n",
    "        triple = tf.gather(train, tIndex)\n",
    "        _head_index = tf.gather(triple,0)\n",
    "        _relation_index = tf.gather(triple,2)\n",
    "        _vHead = tf.gather(nn0,_head_index)\n",
    "        _vRel = tf.gather(nn2,_relation_index)\n",
    "\n",
    "        samples = [tf.slice(total_samples,begin=[tf.math.multiply(tIndex, kns)],size=[kns])]\n",
    "        samples = tf.pad(samples, paddings, constant_values=0)\n",
    "        samples =  tf.cast(samples, tf.int64)         \n",
    "        samples = tf.transpose(tf.concat([samples, [[tf.gather(triple,1)],[1]]], 1))\n",
    "        indices = tf.gather(samples, 0, axis=1)\n",
    "        _nn1_samples = tf.gather(nn1, indices)\n",
    "        _sigmoid =tf.math.sigmoid(tf.tensordot( _nn1_samples , tf.transpose(tf.math.add(_vHead , _vRel)) , axes=1))\n",
    "        cost = tf.math.subtract(tf.cast(tf.gather(samples, 1, axis=1), tf.float64) , _sigmoid)\n",
    "        g = tf.math.multiply(alpha , cost)\n",
    "        g1 = tf.math.multiply(beta , cost)\n",
    "        _nn1_samples = tf.math.add(tf.math.multiply(tf.gather(nn1, indices) , tf.reshape(g, (tf.math.add(kns,1), 1))) , _nn1_samples)\n",
    "        nn1 = tf.tensor_scatter_nd_update(nn1,tf.expand_dims(indices, 1),_nn1_samples)\n",
    "        _nn2_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn1_samples, axis=0, keepdims=False) , _vRel) , tf.reshape(g1, (g1.shape[0], 1))), axis=0, keepdims=False)  , _vRel)\n",
    "        indices = tf.constant(_relation_index)\n",
    "        nn2 = tf.tensor_scatter_nd_update(nn2,tf.expand_dims([indices], 1), tf.reshape(_nn2_sample,(1, _nn2_sample.shape[0])))\n",
    "\n",
    "        indices = tf.constant(_head_index)\n",
    "        _nn0_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn1_samples, axis=0, keepdims=False) , _vHead) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vHead)\n",
    "        nn0 = tf.tensor_scatter_nd_update(nn0,tf.expand_dims([indices], 1), tf.reshape(_nn0_sample,(1, _nn0_sample.shape[0])))\n",
    "    return nn0, nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampleling_head(nn0, nn1, nn2):\n",
    "    paddings = tf.constant([[0, 1,], [0, 0]])\n",
    "    t_row = 10000#train.shape[0]\n",
    "    with tf.device('/cpu:0'):\n",
    "        total_samples  = tf.gather( tf.random.categorical([tf.gather(entities, 2, axis=1)], tf.math.multiply(kns,t_row) , dtype=None, seed=None),0)\n",
    "    for tIndex in range(0 , t_row):\n",
    "        triple = tf.gather(train, tIndex)\n",
    "        _head_index = tf.gather(triple,0)\n",
    "        _tail_index = tf.gather(triple,1)\n",
    "        _relation_index = tf.gather(triple,2)\n",
    "        \n",
    "        _vHead = tf.gather(nn0,_head_index)\n",
    "        _vTail = tf.gather(nn1,_tail_index)\n",
    "        _vRel = tf.gather(nn2,_relation_index)\n",
    "\n",
    "        samples = [tf.slice(total_samples,begin=[tf.math.multiply(tIndex, kns)],size=[kns])]\n",
    "        samples = tf.pad(samples, paddings, constant_values=0)\n",
    "        samples =  tf.cast(samples, tf.int64)         \n",
    "        samples = tf.transpose(tf.concat([samples, [[_head_index],[1]]], 1))\n",
    "        indices = tf.gather(samples, 0, axis=1)\n",
    "        _nn0_samples = tf.gather(nn0, indices)\n",
    "        _sigmoid =tf.math.sigmoid(tf.tensordot( _nn0_samples , tf.transpose(tf.math.add(_vTail , _vRel)) , axes=1))\n",
    "        cost = tf.math.subtract(tf.cast(tf.gather(samples, 1, axis=1), tf.float64) , _sigmoid)\n",
    "        g = tf.math.multiply(alpha , cost)\n",
    "        g1 = tf.math.multiply(beta , cost)\n",
    "\n",
    "        _nn0_samples = tf.math.add(tf.math.multiply(tf.gather(nn0, indices) , tf.reshape(g, (tf.math.add(kns,1), 1))) , _nn0_samples)\n",
    "        nn0 = tf.tensor_scatter_nd_update(nn0,tf.expand_dims(indices, 1),_nn0_samples)\n",
    "\n",
    "        _nn2_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn0_samples, axis=0, keepdims=False) , _vRel) , tf.reshape(g1, (g1.shape[0], 1))), axis=0, keepdims=False)  , _vRel)\n",
    "        indices = tf.constant(_relation_index)\n",
    "        nn2 = tf.tensor_scatter_nd_update(nn2,tf.expand_dims([indices], 1), tf.reshape(_nn2_sample,(1, _nn2_sample.shape[0])))\n",
    "\n",
    "        indices = tf.constant(_tail_index)\n",
    "        _nn1_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn0_samples, axis=0, keepdims=False) , _vTail) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vTail)\n",
    "        nn1 = tf.tensor_scatter_nd_update(nn1,tf.expand_dims([indices], 1), tf.reshape(_nn1_sample,(1, _nn1_sample.shape[0])))\n",
    "    return nn0, nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampleling_rel(nn0, nn1, nn2):\n",
    "    paddings = tf.constant([[0, 1,], [0, 0]])\n",
    "    t_row = 10000#train.shape[0]\n",
    "    with tf.device('/cpu:0'):\n",
    "        total_samples  = tf.gather( tf.random.categorical([tf.gather(relations, 2, axis=1)], tf.math.multiply(kns_r,t_row) , dtype=None, seed=None),0)\n",
    "    for tIndex in range(0 , t_row):\n",
    "        triple = tf.gather(train, tIndex)\n",
    "        _head_index = tf.gather(triple,0)\n",
    "        _tail_index = tf.gather(triple,1)\n",
    "        _relation_index = tf.gather(triple,2)\n",
    "        \n",
    "        _vHead = tf.gather(nn0,_head_index)\n",
    "        _vTail = tf.gather(nn1,_tail_index)\n",
    "        _vRel = tf.gather(nn2,_relation_index)\n",
    "\n",
    "        samples = [tf.slice(total_samples,begin=[tf.math.multiply(tIndex, kns_r)],size=[kns_r])]\n",
    "        samples = tf.pad(samples, paddings, constant_values=0)\n",
    "        samples =  tf.cast(samples, tf.int64)         \n",
    "        samples = tf.transpose(tf.concat([samples, [[_relation_index],[1]]], 1))\n",
    "        indices = tf.gather(samples, 0, axis=1)\n",
    "        _nn2_samples = tf.gather(nn2, indices)\n",
    "        _sigmoid =tf.math.sigmoid(tf.tensordot( _nn2_samples , tf.transpose(tf.math.add(_vTail , _vHead)) , axes=1))\n",
    "        cost = tf.math.subtract(tf.cast(tf.gather(samples, 1, axis=1), tf.float64) , _sigmoid)\n",
    "        g = tf.math.multiply(alpha , cost)\n",
    "        g1 = tf.math.multiply(beta , cost)\n",
    "\n",
    "        _nn2_samples = tf.math.add(tf.math.multiply(tf.gather(nn2, indices) , tf.reshape(g1, (tf.math.add(kns_r,1), 1))) , _nn2_samples)\n",
    "        nn2 = tf.tensor_scatter_nd_update(nn2,tf.expand_dims(indices, 1),_nn2_samples)\n",
    "\n",
    "        _nn0_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn2_samples, axis=0, keepdims=False) , _vHead) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vRel)\n",
    "        indices = tf.constant(_head_index)\n",
    "        nn0 = tf.tensor_scatter_nd_update(nn0,tf.expand_dims([indices], 1), tf.reshape(_nn0_sample,(1, _nn0_sample.shape[0])))\n",
    "\n",
    "        indices = tf.constant(_tail_index)\n",
    "        _nn1_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn2_samples, axis=0, keepdims=False) , _vTail) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vTail)\n",
    "        nn1 = tf.tensor_scatter_nd_update(nn1,tf.expand_dims([indices], 1), tf.reshape(_nn1_sample,(1, _nn1_sample.shape[0])))\n",
    "    return nn0, nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR at iteration   0 ==>   0.000545\n",
      "MRR at iteration   1 ==>   0.000534\n",
      "MRR at iteration   2 ==>   0.000903\n",
      "MRR at iteration   3 ==>   0.001042\n",
      "MRR at iteration   4 ==>   0.000781\n",
      "MRR at iteration   5 ==>   0.001290\n",
      "MRR at iteration   6 ==>   0.001744\n",
      "MRR at iteration   7 ==>   0.002249\n",
      "MRR at iteration   8 ==>   0.001386\n",
      "MRR at iteration   9 ==>   0.001425\n",
      "MRR at iteration  10 ==>   0.001729\n",
      "MRR at iteration  11 ==>   0.001485\n",
      "MRR at iteration  12 ==>   0.001766\n",
      "MRR at iteration  13 ==>   0.001292\n",
      "MRR at iteration  14 ==>   0.001843\n",
      "MRR at iteration  15 ==>   0.001123\n",
      "MRR at iteration  16 ==>   0.000919\n",
      "MRR at iteration  17 ==>   0.000834\n",
      "MRR at iteration  18 ==>   0.002525\n",
      "MRR at iteration  19 ==>   0.002986\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x in range(0 , iteration):\n",
    "    # train = tf.random.shuffle(train, seed=None, name=None)\n",
    "    # if x%3 == 0 :\n",
    "    #     nn0, nn1, nn2 = negative_sampleling_head(nn0, nn1, nn2)\n",
    "    # elif x%3==1:\n",
    "    #     nn0, nn1, nn2 = negative_sampleling_rel(nn0, nn1, nn2)\n",
    "    # else:\n",
    "        # nn0, nn1, nn2 = negative_sampleling_tail(nn0, nn1, nn2)\n",
    "    nn0, nn1, nn2 = negative_sampleling_rel(nn0, nn1, nn2)          \n",
    "    # print(tf.gather(nn0,0))\n",
    "    # if x % 5 == 0 :\n",
    "    #     print(\"Iteration ==> \", x) \n",
    "    # if x % 2 == 0:\n",
    "        # validation = tf.random.shuffle(validation, seed=None, name=None)\n",
    "    tensor = []\n",
    "    for tIndex in range(0 , 30):\n",
    "        triple = tf.gather(validation,tIndex)\n",
    "        tensor.append(calculateRank(triple))\n",
    "    # print(tensor)\n",
    "    print(\"MRR at iteration %3d ==> %10f\" %(x, mrr(tensor))) \n",
    "# FB15k-237\n",
    "# WN18RR        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.sigmoid(tf.tensordot( tf.gather(nn0,6) , tf.transpose(tf.math.add(tf.gather(nn0,87) , tf.gather(nn2,2)\n",
    ")) , axes=1)) \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9237305bcc91a5313a58a70b2212d12fb38f072f1ee5d33405bbdd8883b6ee38"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

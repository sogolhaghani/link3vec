{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 17:53:38.065155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from scipy.stats import rankdata\n",
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 17:53:40.276299: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-13 17:53:40.277294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-13 17:53:40.307072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:40.307366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-06-13 17:53:40.307392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-13 17:53:40.331721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-13 17:53:40.331799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-13 17:53:40.345815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-13 17:53:40.350140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-13 17:53:40.375692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-13 17:53:40.380360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-13 17:53:40.424727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-13 17:53:40.424873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:40.425141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:40.425280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-13 17:53:40.426051: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-13 17:53:40.427481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:40.427842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-06-13 17:53:40.427889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-13 17:53:40.427928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-13 17:53:40.427949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-13 17:53:40.427969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-13 17:53:40.427989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-13 17:53:40.428012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-13 17:53:40.428036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-13 17:53:40.428068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-13 17:53:40.428156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:40.428442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:40.428637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-13 17:53:40.428922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-13 17:53:41.796169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-13 17:53:41.796199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-06-13 17:53:41.796206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-06-13 17:53:41.796800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:41.796995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:41.797159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 17:53:41.797292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5077 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-06-13 17:53:41.798439: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "train = np.load('../data/WN18RR_numpy/train.npy')\n",
    "validation = np.load('../data/WN18RR_numpy/validation.npy')\n",
    "test = np.load('../data/WN18RR_numpy/test.npy')\n",
    "\n",
    "entities = np.load('../data/WN18RR_numpy/entities.npy')\n",
    "relations = np.load('../data/WN18RR_numpy/relations.npy')\n",
    "\n",
    "train = tf.convert_to_tensor(train.astype(dtype=np.int64), dtype=tf.int64)\n",
    "validation = tf.convert_to_tensor(validation.astype(dtype=np.int64), dtype=tf.int64)\n",
    "test = tf.convert_to_tensor(test.astype(dtype=np.int64), dtype=tf.int64)\n",
    "relations = tf.convert_to_tensor(relations.astype(dtype=np.float64), dtype=tf.float64)\n",
    "entities = tf.convert_to_tensor(entities.astype(dtype=np.float64), dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_embedings = True\n",
    "_read_Last_state = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = tf.constant(20)\n",
    "dim = tf.constant(100)\n",
    "kns = tf.constant(2)\n",
    "kns_r = tf.constant(2)\n",
    "alpha = tf.Variable(0.001, dtype = tf.float64)\n",
    "beta = tf.Variable(0.0001, dtype = tf.float64)\n",
    "z = tf.constant(5, dtype = tf.float64)\n",
    "if _read_Last_state:\n",
    "      nn0_numpy = np.load('../data/WN18RR_numpy/nn0.npy')\n",
    "      nn1_numpy = np.load('../data/WN18RR_numpy/nn1.npy')\n",
    "      nn2_numpy = np.load('../data/WN18RR_numpy/nn2.npy')\n",
    "      nn2_numpy = np.load('../data/WN18RR_numpy/nn2.npy')\n",
    "      nn0 = tf.convert_to_tensor(nn0_numpy.astype(dtype=np.float64), dtype=tf.float64)\n",
    "      nn1 = tf.convert_to_tensor(nn1_numpy.astype(dtype=np.float64), dtype=tf.float64)\n",
    "      nn2 = tf.convert_to_tensor(nn2_numpy.astype(dtype=np.float64), dtype=tf.float64)\n",
    "      nn0_numpy = None\n",
    "      nn1_numpy = None\n",
    "      nn2_numpy = None\n",
    "      startIndex= np.load('../data/WN18RR_numpy/x.npy')\n",
    "else:\n",
    "      nn1 = tf.random.uniform( shape=(entities.shape[0], dim),\n",
    "            # minval=tf.math.truediv(z , tf.cast(dim,tf.float64),'minval'), \n",
    "            maxval=tf.math.truediv(z , tf.cast(dim,tf.float64),'maxval'),\n",
    "            dtype=tf.dtypes.float64, seed=1, name='nn1')\n",
    "            \n",
    "      nn0 =tf.random.uniform(shape=(entities.shape[0], dim), \n",
    "            # minval=tf.math.truediv(z , tf.cast(dim,tf.float64),'minval'), \n",
    "            maxval=tf.math.truediv(z , tf.cast(dim,tf.float64),'maxval'),\n",
    "            dtype=tf.dtypes.float64, seed=1, name='nn0')\n",
    "      nn2 = tf.random.uniform(shape=(relations.shape[0], dim), \n",
    "            # minval=tf.math.truediv(z , tf.cast(dim,tf.float64),'minval'), \n",
    "            maxval=tf.math.truediv(z , tf.cast(dim,tf.float64),'maxval'),\n",
    "            dtype=tf.dtypes.float64, seed=1, name='nn2')     \n",
    "      startIndex= 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def calculateRank(triple):  \n",
    "    start = time.time() \n",
    "    selectedEntities = tf.cast(tf.gather(entities, 0, axis=1), dtype=tf.int64)\n",
    "    _head_index = tf.gather(triple,0)\n",
    "    _tail_index = tf.gather(triple,1)\n",
    "    _relation_index = tf.gather(triple,2)  \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(train, 1, axis=1) == _tail_index) , (tf.gather(train, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(train, indexes), 0, axis=1)\n",
    "    shape = tf.constant([entities.shape[0]], dtype=tf.int64)   \n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTrain = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "\n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(test, 1, axis=1) == _tail_index) , (tf.gather(test, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(test, indexes), 0, axis=1)\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTest = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(validation, 1, axis=1) == _tail_index) , (tf.gather(validation, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(validation, indexes), 0, axis=1)\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesvalidation = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "\n",
    "    selectedEntitiesTrain= tf.reshape(selectedEntitiesTrain, (1, selectedEntitiesTrain.shape[0]))\n",
    "    selectedEntitiesTest = tf.reshape(selectedEntitiesTest, (1, selectedEntitiesTest.shape[0]))\n",
    "    selectedEntitiesvalidation = tf.reshape(selectedEntitiesvalidation, (1, selectedEntitiesvalidation.shape[0]))\n",
    "    selectedEntitiesFinal = tf.sets.intersection(selectedEntitiesTrain, selectedEntitiesTest)\n",
    "    selectedEntitiesFinal = tf.cast(tf.sets.intersection(selectedEntitiesFinal, selectedEntitiesvalidation), dtype=tf.int64).values\n",
    "    couraptedH = tf.concat([  tf.reshape(selectedEntitiesFinal, (selectedEntitiesFinal.shape[0], 1)) , tf.fill([selectedEntitiesFinal.shape[0], 1], _tail_index) , tf.fill([selectedEntitiesFinal.shape[0], 1], _relation_index)],1)\n",
    "    couraptedH = tf.concat([couraptedH, tf.reshape(triple, (1,3))], 0)\n",
    "    indexes = None\n",
    "    existEntites = None\n",
    "    selectedEntitiesTrain = None\n",
    "    selectedEntitiesTest = None\n",
    "    selectedEntitiesvalidation = None\n",
    "    selectedEntitiesFinal = None\n",
    "    div = tf.constant(3)\n",
    "    sliceSize = tf.cast(tf.math.floor(tf.math.truediv(couraptedH.shape[0], div)),dtype=tf.int64)\n",
    "    s0, s1, s2= tf.split(couraptedH, num_or_size_splits=[\n",
    "        sliceSize , \n",
    "        sliceSize , \n",
    "        tf.math.subtract(couraptedH.shape[0] , tf.math.multiply(sliceSize, 2)) ], axis=0)\n",
    "    couraptedH = None\n",
    "    # p0 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s0,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s0,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    # p1 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s1,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s1,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    # p2 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s2,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s2,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p0 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn0,tf.gather(s0,1, axis=1),0),tf.transpose(  tf.gather( nn1,  tf.gather( s0,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p1 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn0,tf.gather(s1,1, axis=1),0),tf.transpose(  tf.gather( nn1,  tf.gather( s1,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p2 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn0,tf.gather(s2,1, axis=1),0),tf.transpose(  tf.gather( nn1,  tf.gather( s2,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "\n",
    "    p = tf.math.subtract(1 , tf.concat([p0,p1,p2,], 0))\n",
    "    ranks = rankdata(p.numpy(), method='dense')\n",
    "    # ss = tf.sort(p0, axis=-1, direction='ASCENDING', name=None)\n",
    "    # file1 = open('../data/test.txt', \"w\")\n",
    "    # for x in ss:\n",
    "    #     file1.writelines(str(tf.get_static_value(x)))\n",
    "    #     file1.writelines('\\n')\n",
    "    # file1.close()\n",
    "    rankH = ranks[-1]\n",
    "    p0 = None\n",
    "    p1 = None\n",
    "    p2 = None\n",
    "    p = None\n",
    "\n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(train, 0, axis=1) == _head_index) , (tf.gather(train, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(train, indexes), 1, axis=1)\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTrain = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(test, 0, axis=1) == _head_index) , (tf.gather(test, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(test, indexes), 1, axis=1)\n",
    "\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesTest = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    indexes = tf.where( tf.math.logical_and( (tf.gather(validation, 0, axis=1) == _head_index) , (tf.gather(validation, 2, axis=1) == _relation_index)))\n",
    "    indexes = tf.reshape(indexes, (indexes.shape[0] ))\n",
    "    existEntites = tf.gather(tf.gather(validation, indexes), 1, axis=1)\n",
    "\n",
    "    scatter = tf.scatter_nd(tf.reshape(existEntites ,  (existEntites.shape[0] , 1) ), tf.math.add(existEntites ,1), shape)\n",
    "    selectedEntitiesvalidation = tf.where(tf.math.greater(tf.subtract(selectedEntities , scatter), -1)) \n",
    "    selectedEntitiesTrain= tf.reshape(selectedEntitiesTrain, (1, selectedEntitiesTrain.shape[0]))\n",
    "    selectedEntitiesTest = tf.reshape(selectedEntitiesTest, (1, selectedEntitiesTest.shape[0]))\n",
    "    selectedEntitiesvalidation = tf.reshape(selectedEntitiesvalidation, (1, selectedEntitiesvalidation.shape[0]))\n",
    "\n",
    "    selectedEntitiesFinal = tf.sets.intersection(selectedEntitiesTrain, selectedEntitiesTest)\n",
    "    selectedEntitiesFinal = tf.cast(tf.sets.intersection(selectedEntitiesFinal, selectedEntitiesvalidation), dtype=tf.int64).values\n",
    "    couraptedT = tf.concat([   tf.fill([selectedEntitiesFinal.shape[0], 1], _head_index) , tf.reshape(selectedEntitiesFinal, (selectedEntitiesFinal.shape[0], 1)) , tf.fill([selectedEntitiesFinal.shape[0], 1], _relation_index)],1)\n",
    "    couraptedT = tf.concat([couraptedT, tf.reshape(triple, (1,3))], 0)    \n",
    "    indexes = None\n",
    "    existEntites = None\n",
    "    selectedEntitiesTrain = None\n",
    "    selectedEntitiesTest = None\n",
    "    selectedEntitiesvalidation = None\n",
    "    selectedEntitiesFinal = None\n",
    "    div = tf.constant(3)\n",
    "    sliceSize = tf.cast(tf.math.floor(tf.math.truediv(couraptedT.shape[0], div)),dtype=tf.int64)\n",
    "    s0, s1, s2= tf.split(couraptedT, num_or_size_splits=[\n",
    "        sliceSize , \n",
    "        sliceSize , \n",
    "        tf.math.subtract(couraptedT.shape[0] , tf.math.multiply(sliceSize, 2)) ], axis=0)\n",
    "    couraptedT = None\n",
    "    # p0 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s0,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s0,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    # p1 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s1,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s1,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    # p2 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn1,tf.gather(s2,1, axis=1),0),tf.transpose(  tf.gather( nn0,  tf.gather( s2,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p0 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn0,tf.gather(s0,1, axis=1),0),tf.transpose(  tf.gather( nn1,  tf.gather( s0,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p1 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn0,tf.gather(s1,1, axis=1),0),tf.transpose(  tf.gather( nn1,  tf.gather( s1,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p2 =  tf.linalg.diag_part(tf.math.sigmoid(tf.tensordot(  tf.gather(nn0,tf.gather(s2,1, axis=1),0),tf.transpose(  tf.gather( nn1,  tf.gather( s2,0, axis=1)) + tf.gather(nn2,_relation_index) ),axes=1 )))\n",
    "    p = tf.math.subtract(1 , tf.concat([p0,p1,p2,], 0))\n",
    "    ranks = rankdata(p.numpy(), method='dense')    \n",
    "    rankT = ranks[-1]\n",
    "    # rankT = tf.where(tf.math.top_k( p ,k = p.shape[0]).indices  == tf.subtract(p.shape[0] , 1) )\n",
    "    p = None\n",
    "    # print(rankH, rankT)\n",
    "    if tf.math.greater(rankH , rankT):\n",
    "        return rankT\n",
    "        # return tf.math.add(rankT,1)\n",
    "    else:\n",
    "        return rankH\n",
    "        # return tf.math.add(rankH,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(ranks):\n",
    "    inverse = []\n",
    "    one = tf.constant(1.0, dtype = tf.float64)\n",
    "    for rank in ranks:\n",
    "        inverse.append( tf.math.truediv(one , tf.cast(rank,tf.float64)))\n",
    "    summ = tf.reduce_sum(inverse)\n",
    "    return tf.math.multiply(tf.math.truediv(one , len(inverse)) , summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampleling_tail(nn0, nn1, nn2):\n",
    "    paddings = tf.constant([[0, 1,], [0, 0]])\n",
    "    t_row = 500#train.shape[0]\n",
    "    with tf.device('/cpu:0'):\n",
    "        total_samples  = tf.gather( tf.random.categorical([tf.gather(entities, 2, axis=1)], tf.math.multiply(kns,t_row) , dtype=None, seed=None),0)\n",
    "    for tIndex in range(0 , t_row):\n",
    "        triple = tf.gather(train, tIndex)\n",
    "        _head_index = tf.gather(triple,0)\n",
    "        _relation_index = tf.gather(triple,2)\n",
    "        _vHead = tf.gather(nn0,_head_index)\n",
    "        _vRel = tf.gather(nn2,_relation_index)\n",
    "\n",
    "        samples = [tf.slice(total_samples,begin=[tf.math.multiply(tIndex, kns)],size=[kns])]\n",
    "        samples = tf.pad(samples, paddings, constant_values=0)\n",
    "        samples =  tf.cast(samples, tf.int64)         \n",
    "        samples = tf.transpose(tf.concat([samples, [[tf.gather(triple,1)],[1]]], 1))\n",
    "        indices = tf.gather(samples, 0, axis=1)\n",
    "        _nn1_samples = tf.gather(nn1, indices)\n",
    "        _sigmoid =tf.math.sigmoid(tf.tensordot( _nn1_samples , tf.transpose(tf.math.add(_vHead , _vRel)) , axes=1))\n",
    "        cost = tf.math.subtract(tf.cast(tf.gather(samples, 1, axis=1), tf.float64) , _sigmoid)\n",
    "        g = tf.math.multiply(alpha , cost)\n",
    "        g1 = tf.math.multiply(beta , cost)\n",
    "        _nn1_samples = tf.math.add(tf.math.multiply(tf.gather(nn1, indices) , tf.reshape(g, (tf.math.add(kns,1), 1))) , _nn1_samples)\n",
    "        nn1 = tf.tensor_scatter_nd_update(nn1,tf.expand_dims(indices, 1),_nn1_samples)\n",
    "        _nn2_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn1_samples, axis=0, keepdims=False) , _vRel) , tf.reshape(g1, (g1.shape[0], 1))), axis=0, keepdims=False)  , _vRel)\n",
    "        indices = tf.constant(_relation_index)\n",
    "        nn2 = tf.tensor_scatter_nd_update(nn2,tf.expand_dims([indices], 1), tf.reshape(_nn2_sample,(1, _nn2_sample.shape[0])))\n",
    "\n",
    "        indices = tf.constant(_head_index)\n",
    "        _nn0_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn1_samples, axis=0, keepdims=False) , _vHead) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vHead)\n",
    "        nn0 = tf.tensor_scatter_nd_update(nn0,tf.expand_dims([indices], 1), tf.reshape(_nn0_sample,(1, _nn0_sample.shape[0])))\n",
    "    return nn0, nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampleling_head(nn0, nn1, nn2):\n",
    "    paddings = tf.constant([[0, 1,], [0, 0]])\n",
    "    t_row = 500#train.shape[0]\n",
    "    with tf.device('/cpu:0'):\n",
    "        total_samples  = tf.gather( tf.random.categorical([tf.gather(entities, 2, axis=1)], tf.math.multiply(kns,t_row) , dtype=None, seed=None),0)\n",
    "        total_samples_r  = tf.gather( tf.random.categorical([tf.gather(relations, 2, axis=1)], tf.math.multiply(kns,t_row) , dtype=None, seed=None),0)\n",
    "    for tIndex in range(0 , t_row):\n",
    "        triple = tf.gather(train, tIndex)\n",
    "        _head_index = tf.gather(triple,0)\n",
    "        _tail_index = tf.gather(triple,1)\n",
    "        _relation_index = tf.gather(triple,2)\n",
    "        \n",
    "        _vHead = tf.gather(nn0,_head_index)\n",
    "        _vTail = tf.gather(nn1,_tail_index)\n",
    "        _vRel = tf.gather(nn2,_relation_index)\n",
    "\n",
    "        samples = [tf.slice(total_samples,begin=[tf.math.multiply(tIndex, kns)],size=[kns])]\n",
    "        samples = tf.pad(samples, paddings, constant_values=0)\n",
    "        samples =  tf.cast(samples, tf.int64)         \n",
    "        samples = tf.transpose(tf.concat([samples, [[_head_index],[1]]], 1))\n",
    "        indices = tf.gather(samples, 0, axis=1)\n",
    "        _nn0_samples = tf.gather(nn0, indices)\n",
    "\n",
    "        samples_r = [tf.slice(total_samples_r,begin=[tf.math.multiply(tIndex, kns)],size=[kns])]\n",
    "        samples_r = tf.pad(samples_r, paddings, constant_values=0)\n",
    "        samples_r = tf.cast(samples_r, tf.int64)\n",
    "        samples_r = tf.transpose(tf.concat([samples_r, [[_relation_index],[1]]], 1))\n",
    "        indices_r = tf.gather(samples_r, 0, axis=1)\n",
    "        _nn2_sample = tf.gather(nn2, indices_r)\n",
    "\n",
    "\n",
    "        _sigmoid =tf.math.sigmoid(tf.tensordot( _nn0_samples , tf.transpose(tf.math.add(_vTail , _nn2_sample)) , axes=1))\n",
    "        cost = tf.math.subtract(tf.cast(tf.gather(samples, 1, axis=1), tf.float64) , _sigmoid)\n",
    "        g = tf.linalg.diag_part(tf.math.multiply(alpha , cost))\n",
    "        g1 = tf.linalg.diag_part(tf.math.multiply(beta , cost))\n",
    "\n",
    "        _nn0_samples = tf.math.add(tf.math.multiply(tf.gather(nn0, indices) , tf.reshape(g, (tf.math.add(kns,1), 1))) , _nn0_samples)\n",
    "        nn0 = tf.tensor_scatter_nd_update(nn0,tf.expand_dims(indices, 1),_nn0_samples)\n",
    "\n",
    "        _nn2_sample = tf.math.add(tf.math.multiply(tf.math.add(_nn0_samples , _nn2_sample) , tf.reshape(g1, (g1.shape[0], 1)))  , _nn2_sample)\n",
    "        nn2 = tf.tensor_scatter_nd_update(nn2,tf.expand_dims(indices_r, 1),_nn2_sample)\n",
    "\n",
    "        indices = tf.constant(_tail_index)\n",
    "        _nn1_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn0_samples, axis=0, keepdims=False) , _vTail) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vTail)\n",
    "        nn1 = tf.tensor_scatter_nd_update(nn1,tf.expand_dims([indices], 1), tf.reshape(_nn1_sample,(1, _nn1_sample.shape[0])))\n",
    "    # paddings = tf.constant([[0, 1,], [0, 0]])\n",
    "    # t_row = train.shape[0]\n",
    "    # with tf.device('/cpu:0'):\n",
    "    #     total_samples  = tf.gather( tf.random.categorical([tf.gather(entities, 2, axis=1)], tf.math.multiply(kns,t_row) , dtype=None, seed=None),0)\n",
    "    # for tIndex in range(0 , t_row):\n",
    "    #     triple = tf.gather(train, tIndex)\n",
    "    #     _head_index = tf.gather(triple,0)\n",
    "    #     _tail_index = tf.gather(triple,1)\n",
    "    #     _relation_index = tf.gather(triple,2)\n",
    "        \n",
    "    #     _vHead = tf.gather(nn0,_head_index)\n",
    "    #     _vTail = tf.gather(nn1,_tail_index)\n",
    "    #     _vRel = tf.gather(nn2,_relation_index)\n",
    "\n",
    "    #     samples = [tf.slice(total_samples,begin=[tf.math.multiply(tIndex, kns)],size=[kns])]\n",
    "    #     samples = tf.pad(samples, paddings, constant_values=0)\n",
    "    #     samples =  tf.cast(samples, tf.int64)         \n",
    "    #     samples = tf.transpose(tf.concat([samples, [[_head_index],[1]]], 1))\n",
    "    #     indices = tf.gather(samples, 0, axis=1)\n",
    "    #     _nn0_samples = tf.gather(nn0, indices)\n",
    "    #     _sigmoid =tf.math.sigmoid(tf.tensordot( _nn0_samples , tf.transpose(tf.math.add(_vTail , _vRel)) , axes=1))\n",
    "    #     cost = tf.math.subtract(tf.cast(tf.gather(samples, 1, axis=1), tf.float64) , _sigmoid)\n",
    "    #     g = tf.math.multiply(alpha , cost)\n",
    "    #     g1 = tf.math.multiply(beta , cost)\n",
    "\n",
    "    #     _nn0_samples = tf.math.add(tf.math.multiply(tf.gather(nn0, indices) , tf.reshape(g, (tf.math.add(kns,1), 1))) , _nn0_samples)\n",
    "    #     nn0 = tf.tensor_scatter_nd_update(nn0,tf.expand_dims(indices, 1),_nn0_samples)\n",
    "\n",
    "    #     _nn2_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn0_samples, axis=0, keepdims=False) , _vRel) , tf.reshape(g1, (g1.shape[0], 1))), axis=0, keepdims=False)  , _vRel)\n",
    "    #     indices = tf.constant(_relation_index)\n",
    "    #     nn2 = tf.tensor_scatter_nd_update(nn2,tf.expand_dims([indices], 1), tf.reshape(_nn2_sample,(1, _nn2_sample.shape[0])))\n",
    "\n",
    "    #     indices = tf.constant(_tail_index)\n",
    "    #     _nn1_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn0_samples, axis=0, keepdims=False) , _vTail) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vTail)\n",
    "    #     nn1 = tf.tensor_scatter_nd_update(nn1,tf.expand_dims([indices], 1), tf.reshape(_nn1_sample,(1, _nn1_sample.shape[0])))\n",
    "    return nn0, nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampleling_rel(nn0, nn1, nn2):\n",
    "    paddings = tf.constant([[0, 1,], [0, 0]])\n",
    "    t_row = 500#train.shape[0]\n",
    "    with tf.device('/cpu:0'):\n",
    "        total_samples  = tf.gather( tf.random.categorical([tf.gather(relations, 2, axis=1)], tf.math.multiply(kns_r,t_row) , dtype=None, seed=None),0)\n",
    "        total_samples_t  = tf.gather( tf.random.categorical([tf.gather(entities, 2, axis=1)], tf.math.multiply(kns_r,t_row) , dtype=None, seed=None),0)\n",
    "    for tIndex in range(0 , t_row):\n",
    "        triple = tf.gather(train, tIndex)\n",
    "        _head_index = tf.gather(triple,0)\n",
    "        _tail_index = tf.gather(triple,1)\n",
    "        _relation_index = tf.gather(triple,2)\n",
    "        \n",
    "        _vHead = tf.gather(nn0,_head_index)\n",
    "        _vTail = tf.gather(nn1,_tail_index)\n",
    "        _vRel = tf.gather(nn2,_relation_index)\n",
    "\n",
    "        samples = [tf.slice(total_samples,begin=[tf.math.multiply(tIndex, kns_r)],size=[kns_r])]\n",
    "        samples = tf.pad(samples, paddings, constant_values=0)\n",
    "        samples =  tf.cast(samples, tf.int64)         \n",
    "        samples = tf.transpose(tf.concat([samples, [[_relation_index],[1]]], 1))\n",
    "        indices = tf.gather(samples, 0, axis=1)\n",
    "        _nn2_samples = tf.gather(nn2, indices)\n",
    "\n",
    "        samples_t = [tf.slice(total_samples_t,begin=[tf.math.multiply(tIndex, kns_r)],size=[kns_r])]\n",
    "        samples_t = tf.pad(samples_t, paddings, constant_values=0)\n",
    "        samples_t = tf.cast(samples_t, tf.int64)\n",
    "        samples_t = tf.transpose(tf.concat([samples_t, [[_tail_index],[1]]], 1))\n",
    "        indices_t = tf.gather(samples_t, 0, axis=1)\n",
    "        _nn1_sample = tf.gather(nn1, indices_t)\n",
    "\n",
    "        _sigmoid =tf.math.sigmoid(tf.tensordot( _nn2_samples , tf.transpose(tf.math.add(_vTail , _vHead)) , axes=1))\n",
    "        cost = tf.math.subtract(tf.cast(tf.gather(samples, 1, axis=1), tf.float64) , _sigmoid)\n",
    "        g = tf.math.multiply(alpha , cost)\n",
    "        g1 = tf.math.multiply(beta , cost)\n",
    "\n",
    "        _nn2_samples = tf.math.add(tf.math.multiply(tf.gather(nn2, indices) , tf.reshape(g1, (tf.math.add(kns_r,1), 1))) , _nn2_samples)\n",
    "        nn2 = tf.tensor_scatter_nd_update(nn2,tf.expand_dims(indices, 1),_nn2_samples)\n",
    "\n",
    "        _nn1_sample = tf.math.add(tf.math.multiply(tf.math.add(_nn2_samples , _nn1_sample) , tf.reshape(g1, (g.shape[0], 1)))  , _nn1_sample)\n",
    "        nn1 = tf.tensor_scatter_nd_update(nn1,tf.expand_dims(indices_t, 1),_nn1_sample)\n",
    "\n",
    "        indices = tf.constant(_head_index)\n",
    "        _nn0_sample = tf.math.add(tf.math.reduce_sum(tf.math.multiply(tf.math.add(tf.math.reduce_sum(_nn1_sample, axis=0, keepdims=False) , _vHead) , tf.reshape(g, (g.shape[0], 1))), axis=0, keepdims=False)  , _vHead)\n",
    "        nn0 = tf.tensor_scatter_nd_update(nn0,tf.expand_dims([indices], 1), tf.reshape(_nn0_sample,(1, _nn0_sample.shape[0])))\n",
    "    return nn0, nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 17:53:42.459669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR at iteration validation   0 ==>   0.000162\n",
      "MRR at iteration validation   2 ==>   0.000162\n",
      "MRR at iteration validation   4 ==>   0.000162\n",
      "MRR at iteration validation   6 ==>   0.000163\n",
      "MRR at iteration validation   8 ==>   0.000162\n",
      "MRR at iteration validation  10 ==>   0.000163\n",
      "MRR at iteration validation  12 ==>   0.000163\n",
      "MRR at iteration validation  14 ==>   0.000163\n",
      "MRR at iteration validation  16 ==>   0.000163\n",
      "MRR at iteration validation  18 ==>   0.000163\n"
     ]
    }
   ],
   "source": [
    "for x in range(startIndex , iteration):\n",
    "    train = tf.random.shuffle(train, seed=None, name=None)\n",
    "    if x%3 ==0 :\n",
    "        nn0, nn1, nn2 = negative_sampleling_tail(nn0, nn1, nn2)\n",
    "    elif x%3==1:\n",
    "        nn0, nn1, nn2 = negative_sampleling_rel(nn0, nn1, nn2)\n",
    "    else:\n",
    "        nn0, nn1, nn2 = negative_sampleling_head(nn0, nn1, nn2)\n",
    "    # nn0, nn1, nn2 = negative_sampleling_head(nn0, nn1, nn2)   \n",
    "\n",
    "    if x > 10 and _save_embedings:\n",
    "        np.save('../data/WN18RR_numpy/nn0.npy', nn0.numpy())\n",
    "        np.save('../data/WN18RR_numpy/nn1.npy', nn1.numpy())\n",
    "        np.save('../data/WN18RR_numpy/nn2.npy', nn2.numpy())\n",
    "        np.save('../data/WN18RR_numpy/x.npy',x)\n",
    "    # if x % 5 == 0 :\n",
    "    #     print(\"Iteration ==> \", x) \n",
    "    if tf.math.reduce_all(tf.math.is_nan(nn0)) or tf.math.reduce_all(tf.math.is_nan(nn1)) or tf.math.reduce_all(tf.math.is_nan(nn2)):\n",
    "        print(\"fill with nan\") \n",
    "        break\n",
    "    if x % 2 ==0:\n",
    "        tensor = []\n",
    "        # for tIndex in range(0 , 20):\n",
    "        for tIndex in range(0 ,50):\n",
    "            triple = tf.gather(validation,tIndex)\n",
    "            tensor.append(calculateRank(triple))\n",
    "        print(\"MRR at iteration validation %3d ==> %10f\" %(x, mrr(tensor)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST *** MRR at iteration  19 ==>   0.000313\n"
     ]
    }
   ],
   "source": [
    "tensor = []\n",
    "for tIndex in range(0 ,50):\n",
    "        triple = tf.gather(test,tIndex)\n",
    "        tensor.append(calculateRank(triple))\n",
    "print(\"TEST *** MRR  ==> %10f\" %( mrr(tensor)))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6609, 10851, 16554,  5750,   118,  1825, 40093, 20599, 28883,\n",
       "        7002,  2885,  9724,  1944, 18531,  8694, 31461,  9471,  6744,\n",
       "        6737, 34639, 34137,  3788, 26235, 23988, 19013, 30559, 10517,\n",
       "        8559, 18128,   980, 24221, 14222, 30791,  4395, 14543, 29742,\n",
       "       10149,  2446,  2845, 11536,  8008, 21698,  8625,  4194,  9000,\n",
       "       20067,  3512, 11945, 27828, 27456])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(tensor)\n",
    "# a = a[500:]\n",
    "# a.shape\n",
    "np.save('../data/WN18RR_numpy/rank_test_1.npy',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1_to_1 = []\n",
    "_1_to_N = []\n",
    "_N_to_1 = []\n",
    "_N_to_N = []\n",
    "for tIndex in range(0 ,50):\n",
    "    triple = tf.gather(test,tIndex)\n",
    "    _Head = tf.gather(entities,tf.gather(triple,0))\n",
    "    _Tail = tf.gather(entities,tf.gather(triple,1))\n",
    "    if tf.math.equal(tf.gather(_Head,1),1) and tf.math.equal(tf.gather(_Tail,1),1):\n",
    "        _1_to_1.append(tensor[tIndex])\n",
    "    elif tf.math.equal(tf.gather(_Head,1),1) and tf.math.greater(tf.gather(_Tail,1),1):\n",
    "        _1_to_N.append(tensor[tIndex])\n",
    "    elif tf.math.greater(tf.gather(_Head,1),1) and tf.math.equal(tf.gather(_Tail,1),1):\n",
    "         _N_to_1.append(tensor[tIndex])\n",
    "    else:\n",
    "        _N_to_N.append(tensor[tIndex])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6609,\n",
       " 10851,\n",
       " 16554,\n",
       " 5750,\n",
       " 118,\n",
       " 1825,\n",
       " 40093,\n",
       " 20599,\n",
       " 28883,\n",
       " 7002,\n",
       " 2885,\n",
       " 9724,\n",
       " 1944,\n",
       " 18531,\n",
       " 8694,\n",
       " 31461,\n",
       " 9471,\n",
       " 6744,\n",
       " 6737,\n",
       " 34639,\n",
       " 34137,\n",
       " 3788,\n",
       " 26235,\n",
       " 19013,\n",
       " 30559,\n",
       " 10517,\n",
       " 8559,\n",
       " 18128,\n",
       " 980,\n",
       " 24221,\n",
       " 14222,\n",
       " 30791,\n",
       " 4395,\n",
       " 14543,\n",
       " 29742,\n",
       " 10149,\n",
       " 2446,\n",
       " 2845,\n",
       " 11536,\n",
       " 8008,\n",
       " 4194,\n",
       " 9000,\n",
       " 20067,\n",
       " 3512,\n",
       " 11945,\n",
       " 27828,\n",
       " 27456]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_N_to_N"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f3807b41f1dd5b2dd3ef97aff1934d1fc74c65dc41f378f0e5f9b4b6f88fa84"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

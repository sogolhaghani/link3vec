{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/WN18RR/original/train.txt\",delimiter=\"\\t\", header=None)\n",
    "test = pd.read_csv(\"../data/WN18RR/original/test.txt\",delimiter=\"\\t\", header=None)\n",
    "validation = pd.read_csv(\"../data/WN18RR/original/valid.txt\",delimiter=\"\\t\", header=None)\n",
    "train.columns = ['Header', 'Relation', 'Tail']\n",
    "test.columns = ['Header', 'Relation', 'Tail']\n",
    "validation.columns = ['Header', 'Relation', 'Tail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = pd.concat([train.Header, train.Tail,test.Header, test.Tail, validation.Header, validation.Tail])\n",
    "entities = pd.DataFrame(entities,columns=['ID'])\n",
    "entities = entities.groupby('ID').ID.agg(['count']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = pd.DataFrame([], columns=['ID'])\n",
    "relations['ID'] = pd.concat([train.Relation,test.Relation,validation.Relation])\n",
    "relations = relations.groupby('ID').ID.agg(['count']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Head_idx'] = test.index.map(mapper=(lambda x : entities.index[entities.ID == test.Header[x]].tolist()[0]))\n",
    "test['Tail_idx'] = test.index.map(mapper=(lambda x : entities.index[entities.ID == test.Tail[x]].tolist()[0]))\n",
    "\n",
    "train['Head_idx'] = train.index.map(mapper=(lambda x : entities.index[entities.ID == train.Header[x]].tolist()[0]))\n",
    "train['Tail_idx'] = train.index.map(mapper=(lambda x : entities.index[entities.ID == train.Tail[x]].tolist()[0]))\n",
    "\n",
    "validation['Head_idx'] = validation.index.map(mapper=(lambda x : entities.index[entities.ID == validation.Header[x]].tolist()[0]))\n",
    "validation['Tail_idx'] = validation.index.map(mapper=(lambda x : entities.index[entities.ID == validation.Tail[x]].tolist()[0]))\n",
    "\n",
    "train['Relation_idx'] = train.index.map(mapper=(lambda x : relations.index[relations.ID == train.Relation[x]].tolist()[0]))\n",
    "test['Relation_idx'] = test.index.map(mapper=(lambda x : relations.index[relations.ID == test.Relation[x]].tolist()[0]))\n",
    "validation['Relation_idx'] = validation.index.map(mapper=(lambda x : relations.index[relations.ID == validation.Relation[x]].tolist()[0]))\n",
    "\n",
    "train = train.drop(['Header', 'Tail', 'Relation'], axis=1)\n",
    "test = test.drop(['Header', 'Tail', 'Relation'], axis=1)\n",
    "validation = validation.drop(['Header', 'Tail', 'Relation'], axis=1)\n",
    "\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "validation = validation.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalWords = sum([freq[1] **(3/4) for freq in entities.values])     \n",
    "entities['Probability'] = (entities['count']**(3/4) / totalWords)\n",
    "\n",
    "totalWords = sum([freq[1] **(3/4) for freq in relations.values])     \n",
    "relations['Probability'] = (relations['count']**(3/4) / totalWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.reset_index(level=0, inplace=True)\n",
    "entities = entities.drop(['ID'], axis=1)\n",
    "entities = entities.to_numpy()\n",
    "\n",
    "relations.reset_index(level=0, inplace=True)\n",
    "relations = relations.drop(['ID'], axis=1)\n",
    "relations = relations.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/WN18RR_numpy/train.npy', train)\n",
    "np.save('../data/WN18RR_numpy/validation.npy', validation)\n",
    "np.save('../data/WN18RR_numpy/test.npy', test)\n",
    "\n",
    "np.save('../data/WN18RR_numpy/entities.npy', entities)\n",
    "np.save('../data/WN18RR_numpy/relations.npy', relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1437,  1435,     3],\n",
       "       [ 7360, 16907,     1],\n",
       "       [22576,  3550,     1],\n",
       "       ...,\n",
       "       [ 4407,  4404,     3],\n",
       "       [21464, 21468,     2],\n",
       "       [ 5435,  4179,     9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
